{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae68a4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_44206/3703000730.py:28: DtypeWarning: Columns (17,20,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIAGNOSES_ICD\n",
      "DRGCODES\n",
      "LABEVENTS\n",
      "D_ITEMS\n",
      "D_LABITEMS\n",
      "PROCEDUREEVENTS_MV\n",
      "INPUTEVENTS_MV\n",
      "INPUTEVENTS_CV\n",
      "PATIENTS\n",
      "ICUSTAYS\n",
      "ADMISSIONS\n",
      "MICROBIOLOGYEVENTS\n",
      "CHARTEVENTS\n",
      "SERVICES\n",
      "D_ICD_PROCEDURES\n",
      "CPTEVENTS\n",
      "TRANSFERS\n",
      "OUTPUTEVENTS\n",
      "PRESCRIPTIONS\n",
      "D_ICD_DIAGNOSES\n",
      "DATETIMEEVENTS\n",
      "CAREGIVERS\n",
      "D_CPT\n",
      "CALLOUT\n",
      "NOTEEVENTS\n",
      "PROCEDURES_ICD\n",
      "26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_44206/3703000730.py:28: DtypeWarning: Columns (8,10,13,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from copy import deepcopy\n",
    "from copy import deepcopy\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "def reorder_dataframe_columns(df, preferred_columns):\n",
    "    # Ensure all preferred columns are in the DataFrame\n",
    "    valid_preferred_columns = [col for col in preferred_columns if col in df.columns]\n",
    "    # Get the remaining columns not in preferred_columns, maintaining original order\n",
    "    remaining_columns = [col for col in df.columns if col not in valid_preferred_columns]\n",
    "    # Combine the lists\n",
    "    new_column_order = valid_preferred_columns + remaining_columns\n",
    "    # Reorder the DataFrame and return\n",
    "    return df[new_column_order]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "folder_path = 'data'\n",
    "datasets = {}\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        datasets[os.path.splitext(filename)[0]] = df\n",
    "for el in datasets:\n",
    "    print(el)\n",
    "print(len(datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1f166254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset that contain the column 'subject_id' (20): ['DIAGNOSES_ICD', 'DRGCODES', 'LABEVENTS', 'PROCEDUREEVENTS_MV', 'INPUTEVENTS_MV', 'INPUTEVENTS_CV', 'PATIENTS', 'ICUSTAYS', 'ADMISSIONS', 'MICROBIOLOGYEVENTS', 'CHARTEVENTS', 'SERVICES', 'CPTEVENTS', 'TRANSFERS', 'OUTPUTEVENTS', 'PRESCRIPTIONS', 'DATETIMEEVENTS', 'CALLOUT', 'NOTEEVENTS', 'PROCEDURES_ICD']\n",
      "Other (6): {'D_LABITEMS', 'D_CPT', 'D_ICD_DIAGNOSES', 'CAREGIVERS', 'D_ITEMS', 'D_ICD_PROCEDURES'}\n"
     ]
    }
   ],
   "source": [
    "datasets_with_subject_id = []\n",
    "for name, df in datasets.items():\n",
    "    if 'subject_id' in df.columns:\n",
    "        datasets_with_subject_id.append(name)\n",
    "        \n",
    "other_datasets = set(datasets) - set(datasets_with_subject_id)\n",
    "\n",
    "print(f\"Dataset that contain the column 'subject_id' ({len(datasets_with_subject_id)}): {datasets_with_subject_id}\")\n",
    "print(f\"Other ({len(other_datasets)}): {other_datasets}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "33238d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random `subject_id`: 42412\n"
     ]
    }
   ],
   "source": [
    "df = datasets['PATIENTS']\n",
    "patient_id = random.choice(df['subject_id'].tolist())\n",
    "\n",
    "print(f\"random `subject_id`: {patient_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6091bcd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIAGNOSES_ICD (21, 5) \n",
      "DRGCODES (3, 8) \n",
      "LABEVENTS (950, 9) \n",
      "PROCEDUREEVENTS_MV (5, 25) \n",
      "INPUTEVENTS_MV (12, 31) \n",
      "INPUTEVENTS_CV (0, 22) *EMPTY*\n",
      "PATIENTS (1, 8) \n",
      "ICUSTAYS (1, 12) \n",
      "ADMISSIONS (1, 19) \n",
      "MICROBIOLOGYEVENTS (3, 16) \n",
      "CHARTEVENTS (1573, 15) \n",
      "SERVICES (1, 6) \n",
      "CPTEVENTS (8, 12) \n",
      "TRANSFERS (3, 13) \n",
      "OUTPUTEVENTS (20, 13) \n",
      "PRESCRIPTIONS (45, 19) \n",
      "DATETIMEEVENTS (19, 14) \n",
      "CALLOUT (0, 24) *EMPTY*\n",
      "NOTEEVENTS (0, 11) *EMPTY*\n",
      "PROCEDURES_ICD (2, 5) \n"
     ]
    }
   ],
   "source": [
    "datasets_patient = {}\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    if 'subject_id' in df.columns:\n",
    "        # Filtrare le righe dove 'subject_id' Ã¨ uguale a target_subject_id\n",
    "        filtered_df = df[df['subject_id'] == patient_id]\n",
    "        print(name, filtered_df.shape, end=' ')\n",
    "        # Se ci sono righe filtrate, aggiungerle al dizionario dei dataset filtrati\n",
    "        if not filtered_df.empty:\n",
    "            datasets_patient[name] = filtered_df\n",
    "            print()\n",
    "        else: \n",
    "            print('*EMPTY*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "07df1428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['D_ITEMS', 'D_LABITEMS', 'D_ICD_PROCEDURES', 'D_ICD_DIAGNOSES', 'CAREGIVERS', 'D_CPT'])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_datasets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "11e057c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIAGNOSES_ICD\n",
      "(21, 8)\n",
      "DRGCODES\n",
      "(3, 8)\n",
      "LABEVENTS\n",
      "(950, 14)\n",
      "PROCEDUREEVENTS_MV\n",
      "(5, 37)\n",
      "INPUTEVENTS_MV\n",
      "(12, 43)\n",
      "PATIENTS\n",
      "(1, 8)\n",
      "ICUSTAYS\n",
      "(1, 12)\n",
      "ADMISSIONS\n",
      "(1, 19)\n",
      "MICROBIOLOGYEVENTS\n",
      "(3, 16)\n",
      "CHARTEVENTS\n",
      "(1573, 27)\n",
      "SERVICES\n",
      "(1, 6)\n",
      "CPTEVENTS\n",
      "(8, 12)\n",
      "TRANSFERS\n",
      "(3, 13)\n",
      "OUTPUTEVENTS\n",
      "(20, 25)\n",
      "PRESCRIPTIONS\n",
      "(45, 19)\n",
      "DATETIMEEVENTS\n",
      "(19, 26)\n",
      "PROCEDURES_ICD\n",
      "(2, 8)\n"
     ]
    }
   ],
   "source": [
    "filtered_datasets = {\n",
    "    key: value for key, value in datasets.items() if key not in datasets_with_subject_id\n",
    "}\n",
    "\n",
    "merged_datasets = dict()\n",
    "\n",
    "\n",
    "for el in datasets_patient:\n",
    "    print(el)\n",
    "    m = deepcopy(datasets_patient[el])\n",
    "    if \"cgid\" in m.columns:\n",
    "        m = pd.merge(m, \n",
    "                     filtered_datasets[\"CAREGIVERS\"].add_suffix('_CAREGIVERS').rename(columns={'cgid_CAREGIVERS':'cgid'}), \n",
    "                     on=\"cgid\", \n",
    "                     how=\"left\",)\n",
    "    if \"icd9_code\" in m.columns:\n",
    "        col_type = m[\"icd9_code\"].dtype\n",
    "        if el == \"PROCEDURES_ICD\":\n",
    "            m = pd.merge(\n",
    "                m, \n",
    "                filtered_datasets[\"D_ICD_PROCEDURES\"].add_suffix(\"_D_ICD_PROCEDURES\").rename(columns={'icd9_code_D_ICD_PROCEDURES': 'icd9_code'}), \n",
    "                on=\"icd9_code\", \n",
    "                how=\"left\", \n",
    "            )\n",
    "        else:\n",
    "            m = pd.merge(\n",
    "                m, \n",
    "                filtered_datasets[\"D_ICD_DIAGNOSES\"].add_suffix(\"_D_ICD_DIAGNOSES\").rename(columns={'icd9_code_D_ICD_DIAGNOSES': 'icd9_code'}), \n",
    "                on=\"icd9_code\", \n",
    "                how=\"left\",\n",
    "            )\n",
    "    if \"itemid\" in m.columns:\n",
    "        if el == \"LABEVENTS\":\n",
    "            m = pd.merge(m, \n",
    "                         filtered_datasets[\"D_LABITEMS\"].add_suffix(\"_D_LABITEMS\").rename(columns={'itemid_D_LABITEMS': 'itemid'}), \n",
    "                         on=\"itemid\", \n",
    "                         how=\"left\",\n",
    "                        )\n",
    "        else:\n",
    "            m = pd.merge(m, \n",
    "                         filtered_datasets[\"D_ITEMS\"].add_suffix(\"_D_ITEMS\").rename(columns={'itemid_D_ITEMS': 'itemid'}), \n",
    "                         on=\"itemid\", \n",
    "                         how=\"left\",)\n",
    "    merged_datasets[el] = deepcopy(reorder_dataframe_columns(m, datasets[el].columns))\n",
    "    print(merged_datasets[el].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "caa4606a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged_tables/merged_DIAGNOSES_ICD.xlsx\n",
      "Merged_tables/merged_DRGCODES.xlsx\n",
      "Merged_tables/merged_LABEVENTS.xlsx\n",
      "Merged_tables/merged_PROCEDUREEVENTS_MV.xlsx\n",
      "Merged_tables/merged_INPUTEVENTS_MV.xlsx\n",
      "Merged_tables/merged_PATIENTS.xlsx\n",
      "Merged_tables/merged_ICUSTAYS.xlsx\n",
      "Merged_tables/merged_ADMISSIONS.xlsx\n",
      "Merged_tables/merged_MICROBIOLOGYEVENTS.xlsx\n",
      "Merged_tables/merged_CHARTEVENTS.xlsx\n",
      "Merged_tables/merged_SERVICES.xlsx\n",
      "Merged_tables/merged_CPTEVENTS.xlsx\n",
      "Merged_tables/merged_TRANSFERS.xlsx\n",
      "Merged_tables/merged_OUTPUTEVENTS.xlsx\n",
      "Merged_tables/merged_PRESCRIPTIONS.xlsx\n",
      "Merged_tables/merged_DATETIMEEVENTS.xlsx\n",
      "Merged_tables/merged_PROCEDURES_ICD.xlsx\n"
     ]
    }
   ],
   "source": [
    "file_path = 'Merged_tables'\n",
    "for el in merged_datasets:\n",
    "    file_name = f'{file_path}/merged_{el}.xlsx'\n",
    "    print(file_name)\n",
    "    merged_datasets[el].to_excel(file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b2e555",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
